{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**정확도 1.0 나온 모델 개선**\n",
        "\n",
        "데이터 처리 수정: 음이 빈 데이터를 -1로 채워진 벡터를 추가.\n",
        "\n",
        "모델 학습 후 혼동 행렬 시각화: 모델 예측 결과를 바탕으로 혼동 행렬을 시각화.\n",
        "\n",
        "모델 저장 기능 추가: 학습이 완료된 모델을 로컬 파일로 저장."
      ],
      "metadata": {
        "id": "wHTmm-1uD7Pt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, save_model\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 데이터 불러오기\n",
        "df = pd.read_csv('/content/drive/My Drive/soundAI/df_concat.csv')\n",
        "\n",
        "# 문자열을 실제 텐서로 변환하는 함수\n",
        "def convert_to_tensor(tensor_str):\n",
        "    tensor_list = ast.literal_eval(tensor_str)\n",
        "    tensor = torch.tensor(tensor_list)\n",
        "    return tensor\n",
        "\n",
        "df['feature'] = df['feature'].apply(convert_to_tensor)\n",
        "\n",
        "# 노이즈 추가 함수 정의\n",
        "def add_noise(tensor, noise_level=0.01):\n",
        "    noise = np.random.normal(0, noise_level, tensor.shape)\n",
        "    return tensor + noise\n",
        "\n",
        "# 시간 축 이동 함수 정의\n",
        "def time_shift(tensor, shift_max=2):\n",
        "    shift = np.random.randint(-shift_max, shift_max)\n",
        "    return np.roll(tensor, shift, axis=1)\n",
        "\n",
        "# 시간 축 스케일링 함수 정의\n",
        "def time_stretch(tensor, stretch_factor=0.2):\n",
        "    length = tensor.shape[1]\n",
        "    stretched_length = int(length * (1 + stretch_factor))\n",
        "    stretched_tensor = np.zeros((tensor.shape[0], stretched_length))\n",
        "    for i in range(tensor.shape[0]):\n",
        "        stretched_tensor[i] = np.interp(np.linspace(0, length, stretched_length), np.arange(length), tensor[i])\n",
        "    return stretched_tensor\n",
        "\n",
        "# 데이터 증강 함수\n",
        "def augment_data(df, num_augmentations=10, noise_level=0.01):\n",
        "    augmented_features = []\n",
        "    augmented_labels = []\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        feature = np.array(row['feature'])\n",
        "        label = row['label']\n",
        "\n",
        "        augmented_features.append(feature)\n",
        "        augmented_labels.append(label)\n",
        "\n",
        "        for _ in range(num_augmentations - 1):\n",
        "            augmented_feature = add_noise(feature, noise_level)\n",
        "            augmented_feature = time_shift(augmented_feature)\n",
        "            augmented_feature = time_stretch(augmented_feature)\n",
        "            augmented_features.append(augmented_feature)\n",
        "            augmented_labels.append(label)\n",
        "\n",
        "    augmented_df = pd.DataFrame({\n",
        "        'feature': augmented_features,\n",
        "        'label': augmented_labels\n",
        "    })\n",
        "    return augmented_df\n",
        "\n",
        "# 데이터 증강 실행\n",
        "augmented_df = augment_data(df)\n",
        "\n",
        "# 패딩 함수 정의\n",
        "def pad_feature(feature, target_shape=(1025, 130), pad_value=-1):\n",
        "    current_shape = feature.shape\n",
        "    padded_feature = np.full(target_shape, pad_value)\n",
        "    if current_shape[1] > target_shape[1]:\n",
        "        padded_feature[:, :] = feature[:, :target_shape[1]]\n",
        "    else:\n",
        "        padded_feature[:, :current_shape[1]] = feature\n",
        "    return padded_feature\n",
        "\n",
        "# 빈 데이터를 -1로 채운 벡터 추가\n",
        "def add_empty_data(df, pad_value=-1, target_shape=(1025, 130)):\n",
        "    empty_feature = np.full(target_shape, pad_value)\n",
        "    empty_data = pd.DataFrame({\n",
        "        'feature': [empty_feature for _ in range(df['feature'].shape[0])],\n",
        "        'label': [-1 for _ in range(df['feature'].shape[0])]\n",
        "    })\n",
        "    df = pd.concat([df, empty_data], ignore_index=True)\n",
        "    return df\n",
        "\n",
        "# 데이터 프레임에 빈 데이터 추가\n",
        "df = add_empty_data(df)\n",
        "augmented_df = add_empty_data(augmented_df)\n",
        "\n",
        "# 각 행마다 패딩 적용\n",
        "augmented_df['feature'] = augmented_df['feature'].apply(lambda x: pad_feature(np.array(x)))\n",
        "df['feature'] = df['feature'].apply(lambda x: pad_feature(np.array(x)))\n",
        "\n",
        "# 레이블 매핑\n",
        "unique_labels = np.sort(augmented_df['label'].unique())\n",
        "label_mapping = {old_label: new_label for new_label, old_label in enumerate(unique_labels)}\n",
        "\n",
        "augmented_df['label'] = augmented_df['label'].map(label_mapping)\n",
        "df['label'] = df['label'].map(label_mapping)\n",
        "\n",
        "# 데이터 및 레이블 준비\n",
        "X_train = np.stack(augmented_df['feature'].values)\n",
        "y_train = augmented_df['label'].values\n",
        "\n",
        "X_test = np.stack(df['feature'].values)\n",
        "y_test = df['label'].values\n",
        "\n",
        "X_train = X_train[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "num_classes = len(np.unique(y_train))\n",
        "y_train_categorical = to_categorical(y_train, num_classes)\n",
        "y_test_categorical = to_categorical(y_test, num_classes)\n",
        "\n",
        "# 2D CNN 모델 정의\n",
        "model = Sequential([\n",
        "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(1025, 130, 1)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "    Dropout(0.25),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6JW_znEEDQR",
        "outputId": "daa2265b-ab6f-443a-e130-7e7aa42ecc2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)\n",
        "\n",
        "model.summary()\n",
        "\n",
        "history = model.fit(X_train, y_train_categorical, validation_data=(X_test, y_test_categorical), epochs=100, batch_size=64, callbacks=[reduce_lr])\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test, y_test_categorical)\n",
        "print(f'Test accuracy: {accuracy}')\n",
        "\n",
        "# 정확도와 손실 값을 시각화하는 함수\n",
        "def plot_history(history):\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Accuracy over Epochs')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Train Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Loss over Epochs')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BauWhdSEF18",
        "outputId": "94f6e128-3476-47bc-989a-2ac4e18a4280"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 1023, 128, 32)     320       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 1023, 128, 32)     128       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 511, 64, 32)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 511, 64, 32)       0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 509, 62, 64)       18496     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 509, 62, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 254, 31, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 254, 31, 64)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 252, 29, 128)      73856     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 252, 29, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 126, 14, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 126, 14, 128)      0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 124, 12, 256)      295168    \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 124, 12, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 62, 6, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 62, 6, 256)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 95232)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               48759296  \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 512)               2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 92)                47196     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49198300 (187.68 MB)\n",
            "Trainable params: 49196316 (187.67 MB)\n",
            "Non-trainable params: 1984 (7.75 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "model.save('/content/drive/My Drive/soundAI/model.h5')"
      ],
      "metadata": {
        "id": "O7lC3c9rEJN0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}